#!/bin/bash
#SBATCH --job-name=act_dp_tp       # name
#SBATCH --mem=100G # memory pool for all cores`
#SBATCH --nodes=1                    # nodes
#SBATCH --cpus-per-task=10           # number of cores per tasks
#SBATCH --gres=gpu:a100:1            # number of gpus
#SBATCH --time 23:00:00              # maximum execution time (HH:MM:SS)
#SBATCH --output=./outputs/act_dp_tp_%x-%j.out           # output file name
#SBATCH --error=./outputs/act_dp_tp_%x-%j.err            # error file nameW
#SBATCH --mail-user=xuh0e@kaust.edu.sa #Your Email address assigned for your job
#SBATCH --mail-type=ALL #Receive an email for ALL Job S

task_name=dual_shoes_place
num_epochs=300
chunk_size=20
predict_frame=20
history_step=1

tokenizer_model_temporal_rate=4
lr_schedule_type=cosine_warmup

if [ $predict_frame -eq 1 ]; then
    tokenizer_model_type="DI"
    temporal_downsample_rate=1
else
    tokenizer_model_type="DV"
    temporal_downsample_rate=5
fi
# ['blocks_stack_hard', 'block_handover', 'bottle_adjust', 'container_place', 'diverse_bottles_pick', 'dual_bottles_pick_easy', 'dual_bottles_pick_hard', 'block_hammer_beat', 'block_handover', 'blocks_stack_easy', 'dual_shoes_place', 'empty_cup_place', 'mug_hanging_easy', 'mug_hanging_hard', 'put_apple_cabinet', 'shoe_place','pick_apple_messy']
attention_type=v3
echo "Processing $task_name"
CUDA_VISIBLE_DEVICES=1 python3 train_policy_robotwin.py \
    --task_name  $task_name \
    --ckpt_dir checkpoints/$task_name/act_dp_tp/${chunk_size}_${predict_frame}_${temporal_downsample_rate}_${tokenizer_model_temporal_rate}_${lr_schedule_type}/seed_$seed/num_epochs_$num_epochs \
    --policy_class ACT_diffusion_tp --hidden_dim 512  --batch_size 64 --dim_feedforward 3200 \
    --chunk_size $chunk_size  --norm_type minmax --disable_vae_latent \
    --predict_frame $predict_frame --patch_size 5 --temporal_downsample_rate $temporal_downsample_rate   --prediction_weight 0.2  \
    --tokenizer_model_temporal_rate $tokenizer_model_temporal_rate --tokenizer_model_spatial_rate 8 \
    --num_epochs  $num_epochs --token_pe_type fixed --diffusion_timestep_type cat  \
    --lr 1e-4  --lr_schedule_type $lr_schedule_type --tokenizer_model_type $tokenizer_model_type \
    --seed 0 --num_episodes 10  \
    --kl_weight 10 \
    --dist-url 'tcp://localhost:10001' \
    --world-size 1 \
    --rank 0 \
    --gpu 0  \
    --share_decoder --attention_type $attention_type --history_step $history_step \
    # --disable_multi_view